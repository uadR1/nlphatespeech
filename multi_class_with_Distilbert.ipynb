{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "private_outputs": true,
      "authorship_tag": "ABX9TyPBSCDroKW1kJdrskDDp0A2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uadR1/nlphatespeech/blob/main/multi_class_with_Distilbert.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQ5ww4uKmS8U"
      },
      "outputs": [],
      "source": [
        "# Importing Libraries\n",
        "!pip install transformers\n",
        "from transformers import RobertaTokenizerFast, TFRobertaForSequenceClassification, TFTrainer, TFTrainingArguments, DataCollatorWithPadding\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, matthews_corrcoef\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Read Data \n",
        "df = pd.read_csv('/content/df_all.csv')\n",
        "df.drop(columns=df.columns[0], axis=1, inplace=True)\n",
        "df.head()"
      ],
      "metadata": {
        "id": "-aS9T1S7vbFK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check shape of dataframe \n",
        "df.shape"
      ],
      "metadata": {
        "id": "BwQC2Fnqv1vF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop NA \n",
        "df = df.dropna()"
      ],
      "metadata": {
        "id": "4uRj7mpFwMuL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check distribution of classes\n",
        "df['class'].value_counts()"
      ],
      "metadata": {
        "id": "a1Akk8trwPJF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# layers for multi class  classification \n",
        "\n",
        "# Copy Dataframe first\n",
        "df_multiclass = df.copy()\n",
        "\n",
        "# Replace classes \n",
        "df_multiclass['class'] = np.where((df_multiclass['class'] == 'not_hate'), 0, df_multiclass['class'])\n",
        "df_multiclass['class'] = np.where((df_multiclass['class'] == 'offensive'), 1, df_multiclass['class'])\n",
        "df_multiclass['class'] = np.where((df_multiclass['class'] == 'implicit_hate'), 2, df_multiclass['class'])\n",
        "df_multiclass['class'] = np.where((df_multiclass['class'] == 'explicit_hate'), 3, df_multiclass['class'])\n",
        "\n",
        "# show head \n",
        "df_multiclass.head()"
      ],
      "metadata": {
        "id": "0_FeV0vmwSIz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show Distribution\n",
        "df_multiclass['class'].value_counts()"
      ],
      "metadata": {
        "id": "_eFNDvMfwV-y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get max number of words \n",
        "num_words = df_multiclass['text'].apply(lambda x:len(str(x).split()))\n",
        "print('The comment with the most words consist of', num_words.max(),'words')"
      ],
      "metadata": {
        "id": "I5PdAT8RwYi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize \n",
        "plt.hist(num_words, bins=15)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "syLkIZbmwbY2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create X  \n",
        "X=list(df_multiclass['text']) \n",
        "\n",
        "# Create y \n",
        "y=list(df_multiclass['class']) \n",
        "\n",
        "# Train-Test Split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 123) "
      ],
      "metadata": {
        "id": "QgbBBjtPwd5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "categories=sorted(list(set(y))) #set will return the unique different entries"
      ],
      "metadata": {
        "id": "OjEqvsp8wiBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_categories = len(categories)\n",
        "num_categories"
      ],
      "metadata": {
        "id": "5P2LuHTCwksv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import TFAutoModelForSequenceClassification"
      ],
      "metadata": {
        "id": "FK-olOLx1PGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import DistilBertTokenizerFast\n",
        "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
        "\n",
        "# Tokenize X Train & Test Set \n",
        "train_input = tokenizer(X_train, truncation=True, padding=True, return_tensors='tf')\n",
        "test_input = tokenizer(X_test, truncation=True, padding=True, return_tensors='tf')"
      ],
      "metadata": {
        "id": "8fKRJmyYwoIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(train_input),\n",
        "    y_train\n",
        "))\n",
        "\n",
        "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
        "    dict(test_input),\n",
        "    y_test\n",
        "))"
      ],
      "metadata": {
        "id": "ZCqQgVqEwr0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TFTrainingArguments(\n",
        "    output_dir='./results',          \n",
        "    num_train_epochs=3,              \n",
        "    per_device_train_batch_size=16,  \n",
        "    per_device_eval_batch_size=16,   \n",
        "    warmup_steps = 500,\n",
        "    weight_decay=0.01,\n",
        "    logging_steps=10,\n",
        "    eval_steps = 10\n",
        ")"
      ],
      "metadata": {
        "id": "8cxvMDfFwvkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TFDistilBertForSequenceClassification, TFTrainer, TFTrainingArguments"
      ],
      "metadata": {
        "id": "wdXQn8gO1p_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score"
      ],
      "metadata": {
        "id": "hX4ZDMqK7O3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with training_args.strategy.scope():\n",
        "    model = TFDistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\",num_labels=num_categories)\n",
        "\n",
        "trainer = TFTrainer(\n",
        "    model=model,                         \n",
        "    args=training_args,                  \n",
        "    train_dataset=train_dataset,         \n",
        "    eval_dataset=test_dataset\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "dr5nf3WowyFS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output = trainer.predict(test_dataset)[0]\n",
        "output = np.argmax(output, axis = - 1)"
      ],
      "metadata": {
        "id": "yY0qIXUd86q3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cm=confusion_matrix(y_test,output)\n",
        "cm"
      ],
      "metadata": {
        "id": "Lhps_u69w25f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, output))"
      ],
      "metadata": {
        "id": "ZaSYVUVb5iDe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "plt.rcParams['figure.figsize'] = (10, 10)\n",
        "confusion_matrix = metrics.confusion_matrix(y_test, output)\n",
        "\n",
        "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix, display_labels = [\"not_hate\", \"offensive\", \"implicit\", \"explicit\" ])\n",
        "\n",
        "cm_display.plot()"
      ],
      "metadata": {
        "id": "D9w__9vd5poD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}